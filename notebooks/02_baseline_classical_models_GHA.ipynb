{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **02 - Baseline & Classical Models**\n",
        "**Goal**: Implement baseline + classical forecasting models for hourly temperature (1-7 day horizons)\n",
        "\n",
        "**Models**:\n",
        "- **Baseline**: Naive, Seasonal Naive\n",
        "- **Classical**: SARIMA, Exponential Smoothing\n",
        "\n",
        "**Evaluation**: RMSE, MAE across 24/48/72/96/120/144/168 hour horizons"
      ],
      "metadata": {
        "id": "kkNDQ2yte5em"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1: Setup & Load Data\n",
        "\n",
        "Load cleaned hourly temperature data created."
      ],
      "metadata": {
        "id": "AolSeFVLLIQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load processed data from Member 1 (automatic download)\n",
        "url = \"https://raw.githubusercontent.com/aejae-da/weather-forecasting-project-gha/main/data/weather_temperature_hourly.csv\"\n",
        "df = pd.read_csv(url, parse_dates=['date'])\n",
        "print(f\"‚úÖ Loaded Member 1 data: {df.shape}\")\n",
        "print(\"Columns:\", list(df.columns))\n",
        "df.head()"
      ],
      "metadata": {
        "id": "91yqTpaRi1mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Train/Test Split\n",
        "\n",
        "**Split**: 80% train + last 7 days test"
      ],
      "metadata": {
        "id": "MenH49RxLg55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use last 7 days for testing (168 hours)\n",
        "test_size = 24 * 7  # 168 hours\n",
        "train = df.iloc[:-test_size].copy()\n",
        "test = df.iloc[-test_size:].copy()\n",
        "\n",
        "print(f\"Train: {len(train)} hours ({len(train)/24:.1f} days)\")\n",
        "print(f\"Test:  {len(test)} hours (7 days)\")\n",
        "print(f\"Train period: {train['date'].min().date()} to {train['date'].max().date()}\")"
      ],
      "metadata": {
        "id": "mNkK1IQZjqMA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Baseline Models\n",
        "\n",
        "**Naive**: Repeat last observed value  \n",
        "**Seasonal Naive**: Repeat last 24h pattern\n",
        "\n",
        "*Baseline = \"what not to beat\"*"
      ],
      "metadata": {
        "id": "PunNtN99LqTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create forecasts for 7 horizons: 24,48,72,96,120,144,168 hours\n",
        "horizons = [24, 48, 72, 96, 120, 144, 168]\n",
        "\n",
        "results = {}\n",
        "\n",
        "# 3.1 Naive (last observed value)\n",
        "naive_forecasts = {}\n",
        "for h in horizons:\n",
        "    last_value = train['y'].iloc[-1]\n",
        "    naive_forecasts[h] = [last_value] * h\n",
        "    mae = mean_absolute_error(test['y'].iloc[:h], naive_forecasts[h])\n",
        "    rmse = np.sqrt(mean_squared_error(test['y'].iloc[:h], naive_forecasts[h]))\n",
        "    results[f'Naive_h{h}'] = {'MAE': mae, 'RMSE': rmse}\n",
        "\n",
        "print(\"‚úÖ Naive baseline complete\")"
      ],
      "metadata": {
        "id": "-YID7laKjrPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3.2 Seasonal Naive (last 24h pattern repeats)\n",
        "seasonal_forecasts = {}\n",
        "for h in horizons:\n",
        "    pattern = train['y'].iloc[-24:].values  # Last 24 hours\n",
        "    forecast = np.tile(pattern, (h//24 + 1))[:h]\n",
        "    seasonal_forecasts[h] = forecast\n",
        "    mae = mean_absolute_error(test['y'].iloc[:h], forecast)\n",
        "    rmse = np.sqrt(mean_squared_error(test['y'].iloc[:h], forecast))\n",
        "    results[f'Seasonal_h{h}'] = {'MAE': mae, 'RMSE': rmse}\n",
        "\n",
        "print(\"‚úÖ Seasonal naive complete\")"
      ],
      "metadata": {
        "id": "xoWJ59ZzjuDn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Classical Models (SARIMA)\n",
        "\n",
        "**SARIMA(1,1,1)(1,1,1,24)**  \n",
        "- Order (1,1,1): AR, differencing, MA  \n",
        "- Seasonal (1,1,1,24): Daily cycles"
      ],
      "metadata": {
        "id": "dAGIkDnaL0pG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# SARIMA(1,1,1)(1,1,1,24) - daily seasonality\n",
        "print(\"Training SARIMA... (this takes ~2-3 minutes)\")\n",
        "sarima_model = SARIMAX(train['y'], order=(1,1,1), seasonal_order=(1,1,1,24))\n",
        "sarima_fit = sarima_model.fit(disp=False)\n",
        "\n",
        "sarima_forecasts = {}\n",
        "for h in horizons:\n",
        "    forecast = sarima_fit.forecast(steps=h)\n",
        "    sarima_forecasts[h] = forecast\n",
        "    mae = mean_absolute_error(test['y'].iloc[:h], forecast)\n",
        "    rmse = np.sqrt(mean_squared_error(test['y'].iloc[:h], forecast))\n",
        "    results[f'SARIMA_h{h}'] = {'MAE': mae, 'RMSE': rmse}\n",
        "\n",
        "print(\"‚úÖ SARIMA complete\")"
      ],
      "metadata": {
        "id": "Llww-fQujwdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Exponential Smoothing\n",
        "\n",
        "**ETS(A,A,A,24)**: Additive trend + daily seasonality\n",
        "\n",
        "*Fast alternative to SARIMA*"
      ],
      "metadata": {
        "id": "RMs5A-yKL9BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
        "\n",
        "# ETS with daily seasonality\n",
        "print(\"Training Exponential Smoothing...\")\n",
        "ets_model = ExponentialSmoothing(train['y'],\n",
        "                                trend='add',\n",
        "                                seasonal='add',\n",
        "                                seasonal_periods=24)\n",
        "ets_fit = ets_model.fit()\n",
        "\n",
        "ets_forecasts = {}\n",
        "for h in horizons:\n",
        "    forecast = ets_fit.forecast(steps=h)\n",
        "    ets_forecasts[h] = forecast\n",
        "    mae = mean_absolute_error(test['y'].iloc[:h], forecast)\n",
        "    rmse = np.sqrt(mean_squared_error(test['y'].iloc[:h], forecast))\n",
        "    results[f'ETS_h{h}'] = {'MAE': mae, 'RMSE': rmse}\n",
        "\n",
        "print(\"‚úÖ ETS complete\")"
      ],
      "metadata": {
        "id": "yn27_7-mj0D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Results Table\n",
        "\n",
        "Compare all 4 models across 7 horizons"
      ],
      "metadata": {
        "id": "99gDd5FWMD9m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame(results).T\n",
        "results_df = results_df.round(3)\n",
        "print(\"\\nüìä MODEL COMPARISON (Test Set)\")\n",
        "print(results_df)\n",
        "\n",
        "# Best models per horizon\n",
        "print(\"\\nüèÜ BEST MODEL PER HORIZON:\")\n",
        "for h in horizons:\n",
        "    best_model = results_df.loc[[f'Naive_h{h}', f'Seasonal_h{h}', f'SARIMA_h{h}', f'ETS_h{h}'], 'RMSE'].idxmin()\n",
        "    best_rmse = results_df.loc[best_model, 'RMSE']\n",
        "    print(f\"H{h:2d}h: {best_model:10s} (RMSE={best_rmse:.3f})\")"
      ],
      "metadata": {
        "id": "KD08moN7j3s1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Visualization\n",
        "\n",
        "48-hour forecasts vs actual temperature"
      ],
      "metadata": {
        "id": "igG8HskZMKZM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot best forecasts vs actual (48h horizon example)\n",
        "h_example = 48\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# Naive\n",
        "axes[0,0].plot(test['date'].iloc[:h_example], test['y'].iloc[:h_example], label='Actual', linewidth=2)\n",
        "axes[0,0].plot(test['date'].iloc[:h_example], naive_forecasts[h_example], label='Naive', linestyle='--')\n",
        "axes[0,0].set_title(f'Naive Baseline (H{h_example})')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(alpha=0.3)\n",
        "\n",
        "# Seasonal Naive\n",
        "axes[0,1].plot(test['date'].iloc[:h_example], test['y'].iloc[:h_example], label='Actual', linewidth=2)\n",
        "axes[0,1].plot(test['date'].iloc[:h_example], seasonal_forecasts[h_example], label='Seasonal Naive', linestyle='--')\n",
        "axes[0,1].set_title(f'Seasonal Naive (H{h_example})')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(alpha=0.3)\n",
        "\n",
        "# SARIMA\n",
        "axes[1,0].plot(test['date'].iloc[:h_example], test['y'].iloc[:h_example], label='Actual', linewidth=2)\n",
        "axes[1,0].plot(test['date'].iloc[:h_example], sarima_forecasts[h_example], label='SARIMA', linestyle='--')\n",
        "axes[1,0].set_title(f'SARIMA (H{h_example})')\n",
        "axes[1,0].legend()\n",
        "axes[1,0].grid(alpha=0.3)\n",
        "\n",
        "# ETS\n",
        "axes[1,1].plot(test['date'].iloc[:h_example], test['y'].iloc[:h_example], label='Actual', linewidth=2)\n",
        "axes[1,1].plot(test['date'].iloc[:h_example], ets_forecasts[h_example], label='ETS', linestyle='--')\n",
        "axes[1,1].set_title(f'Exponential Smoothing (H{h_example})')\n",
        "axes[1,1].legend()\n",
        "axes[1,1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T42-qny_j56g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 8: Save Results\n",
        "\n",
        "**Saved**:\n",
        "- `baseline_classical_results.csv` ‚Üê Metrics table\n",
        "- `baseline_classical_forecasts.csv` ‚Üê Raw predictions"
      ],
      "metadata": {
        "id": "zGXyRWxtMT7y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results table\n",
        "results_df.to_csv('baseline_classical_results.csv')\n",
        "print(\"‚úÖ Saved: baseline_classical_results.csv\")\n",
        "\n",
        "# Save forecasts (for plotting later)\n",
        "forecasts_df = pd.DataFrame({\n",
        "    'date': test['date'].iloc[:168].values,\n",
        "    'actual': test['y'].iloc[:168].values,\n",
        "    'naive': naive_forecasts[168],\n",
        "    'seasonal': seasonal_forecasts[168],\n",
        "    'sarima': sarima_forecasts[168],\n",
        "    'ets': ets_forecasts[168]\n",
        "})\n",
        "forecasts_df.to_csv('baseline_classical_forecasts.csv', index=False)\n",
        "print(\"‚úÖ Saved: baseline_classical_forecasts.csv\")\n",
        "\n",
        "from google.colab import files\n",
        "files.download('baseline_classical_results.csv')\n",
        "files.download('baseline_classical_forecasts.csv')"
      ],
      "metadata": {
        "id": "zkyPM5cqj9hM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}